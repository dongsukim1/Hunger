Hunger Project Progress Summary (as of current session)

Completed Work

1) Generation + training execution support
- Ran synthetic generation with requested parameters and confirmed outputs.
- Ran model training multiple times and captured MAE/AUC outputs.

2) Fixed training/inference feature schema mismatch
- Added feature schema artifact saving in `data/ML_recs/train_model.py` -> `rating_model_features.json`.
- Added schema saving in `data/ML_recs/retrain.py`.
- Updated inference in `backend/recommendation_engine.py` to build feature vectors by saved schema column names/order.
- Result: model input ordering is now consistent between training and inference.

3) Fixed ML question option bug
- In `backend/recommendation_engine.py`, `select_best_question_ml(...)` previously returned options using loop-last `unique_vals`.
- Patched to track and return `best_values` for the selected `best_attr`.
- Result: question options now align with selected attribute.

4) Fixed context alignment issues
- Added context normalization in inference (`backend/recommendation_engine.py`) so unknown contexts map to known model contexts.
- Added context normalization in retrain (`data/ML_recs/retrain.py`) so arbitrary list names do not drift context columns.
- Result: training/retraining/inference context semantics are now aligned.

5) Reduced metric leakage from duplicate rows during evaluation
- Replaced random row split in `data/ML_recs/train_model.py` with grouped split (`GroupShuffleSplit`) using feature-row hashes.
- Added safe AUC handling when test split is single-class.
- Result: evaluation is less inflated by identical rows appearing in both train and test.

6) Refactored synthetic generator toward more realistic cold-start data
- Extended personas (`data/personas.py`) with:
  - `strictness`
  - `generosity_bias`
  - `context_preferences`
  - `sample_user_context(...)`
- Reworked session simulation (`data/session_simulator.py`) with:
  - soft filtering (not hard deterministic filtering)
  - exposure stage before ratings
  - latent popularity/quality signals
  - sparse feedback probability
  - ordinal utility->rating mapping
  - surprise/noise behavior
- Updated generator (`data/generate.py`) with new knobs and diagnostics:
  - `--top-k`, `--max-questions`, `--rating-probability`, `--surprise-rate`
  - prints rating histogram, %>=4, context means, user quantiles, duplicate-feature fraction
- Observed after regeneration into training path:
  - 253,265 ratings
  - %>=4 reduced to ~76.0% (from highly top-heavy prior)
  - duplicate feature-row fraction still high (~0.9949)

7) Implemented model hot-reload and tag abstraction groundwork
- Added in-memory model reload function + lock in `backend/recommendation_engine.py`.
- Hooked startup retrain to reload model artifacts in `backend/lifespan.py`.
- Added canonical `restaurant_features` table in `backend/database.py`.
- Updated loader (`data/data_loader.py`) to prefer canonical features and fallback to synthetic via `COALESCE`.
- Updated backend candidate load path to use shared loader.
- Result: system can transition away from synthetic tag dependency with minimal downstream changes.


What Remains (Highest Impact)

1) Duplicate-feature concentration reduction in synthetic generation
- Despite better realism, feature duplication remains very high.
- Need stronger diversification in exposure/session trajectories and possibly additional varying features (distance buckets, session-level perturbations, etc.).

2) True no-synthetic-tag migration
- Current loader still includes fallback to `synthetic_attributes` for compatibility.
- Need a migration phase where `restaurant_features` is fully populated and fallback path is removed.

3) Runtime retrain reload behavior beyond startup lifecycle
- Hot-reload is wired after startup retrain path.
- If retrain is triggered elsewhere in future, ensure `reload_model_artifacts()` is called there too.

4) Recommendation objective improvements
- `select_best_question_ml(...)` still uses a simple expected score proxy.
- Improve with answer-probability weighting and top-k utility objective.

5) Recommendation-focused evaluation expansion
- Add NDCG@k / hit-rate@k / precision@k, plus calibration checks.


Distilled Optimized Prompt For Next Improvement Cycle

"You are working in the Hunger codebase. Do not redesign architecture unless necessary. Focus on high-impact, low-churn improvements.

Goals:
1) Reduce duplicate feature-row concentration in synthetic training data while keeping data synthetic and cold-start friendly.
2) Prepare for full removal of synthetic tags by finalizing canonical restaurant feature usage.
3) Keep training/inference schema stability and model reload behavior intact.

Constraints:
- Preserve existing CSV training contract: user_id, context, restaurant_id, rating.
- Preserve existing model artifact paths (`rating_model.json`, `rating_model_features.json`).
- Keep changes backwards-compatible unless explicitly migrating.

Tasks:
1) Improve synthetic diversity in `data/session_simulator.py` and `data/generate.py`:
   - Add controlled variability that changes feature combinations materially.
   - Reduce repeated identical context+restaurant feature patterns.
   - Keep diagnostics printing duplicate-feature fraction.
2) Add migration utilities for `restaurant_features` population:
   - Add script to backfill canonical table from current sources.
   - Add validation report for null/missing canonical fields.
3) Add a feature-flagged cutover mode:
   - Mode A: canonical+fallback (current)
   - Mode B: canonical-only (no synthetic fallback)
4) Add evaluation checks:
   - Track MAE/AUC plus NDCG@k and hit-rate@k on held-out grouped split.
5) Verify end-to-end:
   - generate -> train -> inference smoke tests.

Deliverables:
- Code changes with concise comments.
- Before/after diagnostics summary.
- Explicit statement of remaining risks and next step recommendation."
